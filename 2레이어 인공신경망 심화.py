# -*- coding: utf-8 -*-
"""3. 2레이어 인공신경망 심화_제출용.ipynb의 사본

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y7u3XvVYfAFUJ-vXCaGy2MvqNy2co5rs

# [코드리뷰 프로젝트] 2. 2레이어 인공신경망 심화

## 0. 모델 세팅 & 포워딩 연산 구현하기
"""

import numpy as np # numpy import
X = np.array([0, 0, 1, 1, 0, 1, 0, 1]).reshape(2,4) # 입력
Y = np.array([0, 1, 1, 0]).reshape(1,4) # 정답

print(X)
print(Y)

# 가중치 초기화 함수
def init_parameters(num_hidden_units = 2):
  W1 = np.random.randn(2, num_hidden_units) # 첫번째 레이어 가중치
  B1 = np.zeros((num_hidden_units,1)) # 첫번째 레이어 바이어스
  W2 = np.random.randn(num_hidden_units, 1) # 두번째 레이어 가중치
  B2 = np.zeros((1, 1)) # 두번째 레이어의 바이어스
  return W1, B1, W2, B2 # 가중치 파라미터 리턴

#--------------------------------------------------------------------------------------------------------------------------------------
def affine(W, X, B):
  return np.dot(np.transpose(W), X) + B

# sigmoid function을 구현하세요.
def sigmoid(z):
  return 1 / (1 + np.exp(-z))

w = np.arange(4).reshape(2,2)
b = [[1],[2]]
x = [[1],[1]]

print(affine(w, x, b)) # affine test -> [[3],[6]]

print(sigmoid(0.1)) # sigmoide test -> 0.524979

"""## 1. 손실함수 만들기

### [TODO] 1_ 이진 크로스 엔트로피 (Binary Cross Entropy)
"""

#######################################
#### 3-1. 알맞은 코드를 직접 작성해보세요! ####
#######################################

def binary_cross_entropy(Y, YHat):
  N = Y.shape[1] # 총 샘플의 수
  loss = - (1 / N) * np.sum(Y * np.log(YHat) + (1 - Y) * np.log(1 - YHat))
  return loss

# 정답 확인
Y = np.array([0, 1, 1, 0]).reshape(1, 4) # 정답
YHat = np.array([0.5, 0.5, 0.5, 0.5]).reshape(1, 4) # 추정값

loss = binary_cross_entropy(Y, YHat)
print("2진 크로스엔트로피 비용:", loss)

"""## 2. 순방향(forward) 및 역방향(backward) 연산 구현하기

### [TODO] 2_ 2레이어 순방향 연산 함수 구현하기
"""

#######################################
#### 3-2. 알맞은 코드를 직접 작성해보세요! ####
#######################################

def forward_loss(X, Y, _params):
  W1, B1, W2, B2 = _params

  # 첫번째 레이어연산
  Z1 = affine(W1, X, B1)
  H = sigmoid(Z1)

  # 두번째 레이어 연산
  Z2 = affine(W2, H, B2)
  YHat = sigmoid(Z2)

  # 손실함수 계산
  loss = binary_cross_entropy(Y, YHat)

  return Z1, H, Z2, YHat, loss

np.random.seed(42) # random seed로 고정
W1, B1, W2, B2 = init_parameters(num_hidden_units = 2) # 파라미터 초기화
forward_loss(X, Y, [W1, B1, W2, B2])[-1] # loss출력 : 0.70492209

"""### [TODO] 5_ 2레이어 뉴럴네트워크의 역방향 연산 함수 구현하기"""

#######################################
#### 3-3. 알맞은 코드를 직접 작성해보세요! ####
#######################################

def get_gradients(X, Y, _params):
  W1, B1, W2, B2 = _params
  m = X.shape[1] # 샘플의 수
  # 포워드 함수 통과 후 출력
    # - Z1 : 첫번재 레이어 affine 결과
    # - H : 첫번재 레이어 sigmoid 통과한 결과

    # - Z2 : 두번재 레이어 affine 통과한 결과
    # - YHat : 두번재 레이어 sigmoid 통과한 결과
    # - loss : 크로스엔트로피 손실값
  Z1, H, Z2, YHat, loss = forward_loss(X, Y, _params)

  # 1) dLoss/dZ2 구현. 손실함수가 각 샘플 손실의 평균으로 계산되기 때문에 그대로 구현하였습니다.
  dLdZ2 = YHat-Y # 그림에서 1의 구현

  # 2) dLoss/dW2의 구현 - '...'을 구현하세요.
  dLdW2 = np.dot(H, dLdZ2.T) # 그림에서 2의 구현 (초록색 2번 참고)

  # 3) dLoss/dB2의 구현 - 샘플마다 gradient가 있음. 따라서 합쳐줘야 함.
  dLdB2 = np.sum(dLdZ2, axis=1, keepdims=True) # 그림에서 3의 구현

  # 4) dLoss/dH의 구현 - '...'을 구현하세요.
  dLdH = np.dot(W2, dLdZ2) #  그림에서 4의 구현

  # 5) dLoss/dZ1의 구현 - '...'을 구현하세요.
  dLdZ1 = dLdH * H * (1 - H) # 그림에서 5의 구현

  # 6) dLoss/dW1의 구현 - '...'을 구현하세요.
  dLdW1 = np.dot(X, dLdZ1.T) # 그림에서 6의 구현

  # 7) dLoss/dB2의 구현 - '...'을 구현하세요.
  dLdB1 = np.sum(dLdZ1, axis=1, keepdims=True)

  return [dLdW1, dLdB1, dLdW2, dLdB2], loss

"""## 3. 모델 학습하기"""

import copy
def optimize (X, Y, _params, learning_rate = 0.1, iteration = 1000):
    params = copy.deepcopy(_params)
    loss_trace = [] # 손실 값 저장

    for epoch in range(iteration): # 학습 반복
        dparams, loss = get_gradients(X, Y, params) # 그레디언트 추출
        for param, dparam in zip(params, dparams):
            param += - learning_rate * dparam # 경사하강법 구현

        if (epoch % 100 == 0): # 손실값 저장
            loss_trace.append(loss)

    _, _, _, Y_hat_predict, _ = forward_loss(X, Y, params) # 학습된 모델로 추론

    return params, loss_trace, Y_hat_predict

X = np.array([0, 0, 1, 1, 0, 1, 0, 1]).reshape(2,4) # 입력
Y = np.array([0, 1, 1, 0]).reshape(1,4) # 정답

params = init_parameters(2) # 파라미터 세팅
new_params, loss_trace, Y_hat_predict = optimize(X, Y, params, 0.1, 150000) # 학습 및 추론

print(Y_hat_predict) # 정답 Y와 유사한 값이 나왔다면 학습이 잘 진행된 것 입니다.

import matplotlib.pyplot as plt

# Plot learning curve (with costs)
plt.plot(loss_trace)
plt.ylabel('loss')
plt.xlabel('iterations (per hundreds)')
plt.show()

"""## 4. 코드리뷰 프로젝트 제출하기

- 수행한 프로젝트 내용을 확인하고, 전체 코드를 파이썬 파일(.py)로 저장합니다.
- 다운로드 받은 .py 파일을 zip으로 압축 및 제출하여 수행여부를 증빙합니다.
- 이번 차시에 궁금한 점이 있다면, 본문에 내용을 함께 작성하여 제출할 수 있습니다.

ALL RIGHTS RESERVED. (C)NAVER Connect Foundation.
"""